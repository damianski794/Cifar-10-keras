{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43498da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod, abstractstaticmethod\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import (\n",
    "    Conv2D,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    Flatten,\n",
    "    Input,\n",
    "    MaxPool2D,\n",
    "    RandomContrast,\n",
    "    RandomFlip,\n",
    "    RandomRotation, # zamula\n",
    "    RandomTranslation,\n",
    "    RandomZoom\n",
    ")\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42e35b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if GPU is detected:\n",
    "len(tf.config.list_physical_devices('GPU')) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1cc42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150ba766",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "x_train = x_train/255.0  # normalization\n",
    "x_test = x_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd7e057",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba783a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConvModel(keras.Model):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(kwargs)\n",
    "        \n",
    "        \n",
    "    #def build(self, inputs):\n",
    "        self.conv2D_1 = Conv2D(filters=32,kernel_size=(4,4),input_shape=(32,32,3),activation='relu')\n",
    "        self.max_pool2D_1 = MaxPool2D(pool_size=(2,2))\n",
    "        self.conv2D_2 = Conv2D(filters=32,kernel_size=(4,4),input_shape=(32,32,3),activation='relu')\n",
    "        self.max_pool2D_2 = MaxPool2D(pool_size=(2,2))\n",
    "        self.flatten = Flatten()\n",
    "        self.dense_1 = Dense(256,activation='relu')\n",
    "        self.dense_2 = Dense(10,activation='softmax')\n",
    "        #self.dropout = Dropout(0.3)\n",
    "        \n",
    "    def call(self, inputs, training=True):\n",
    "        print(inputs)\n",
    "        x =  self.conv2D_1(inputs)\n",
    "        x = self.max_pool2D_1(x)\n",
    "        x = self.conv2D_2(x)\n",
    "        x = self.max_pool2D_2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense_1(x)\n",
    "        x = self.dense_2(x)\n",
    "        return x        \n",
    "        \n",
    "        \n",
    "#simple_conv_model  = SimpleConvModel(inputs=Input((32,32,3)))\n",
    "simple_conv_model  = SimpleConvModel()\n",
    "simple_conv_model.build((None,32,32,3))\n",
    "#simple_conv_model.build(inputs=(32,32,3))\n",
    "simple_conv_model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "simple_conv_model.summary()\n",
    "#early_stopping = EarlyStopping(monitor='val_loss',\n",
    "#                               min_delta=0,\n",
    "#                               patience=10,\n",
    "#                               verbose=1,\n",
    "#                              )\n",
    "\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=20)\n",
    "checkpoint_callback = ModelCheckpoint('models/SimpleConvModel', \n",
    "                                      monitor='val_loss', \n",
    "                                      verbose=1, \n",
    "                                      save_best_only=True, \n",
    "                                      mode='min',\n",
    "                                      save_format='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ea8c6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = simple_conv_model.fit(\n",
    "                      x=x_train, \n",
    "                      y=y_train, \n",
    "                      batch_size=512, \n",
    "                      validation_split=0.2, \n",
    "                      epochs=100,#,\n",
    "                      callbacks=[early_stopping_callback, checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109986dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_simple_model = keras.models.load_model('models/SimpleConvModel')\n",
    "new_simple_model.evaluate(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83b7bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_conv_model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb53129a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55156231",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cc6977",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4c94f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConvModelDropout(keras.Model):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(kwargs)\n",
    "        self.conv2D_1 = Conv2D(filters=32,kernel_size=(4,4),input_shape=(32,32,3),activation='relu')\n",
    "        self.max_pool2D_1 = MaxPool2D(pool_size=(2,2))\n",
    "        self.conv2D_2 = Conv2D(filters=32,kernel_size=(4,4),input_shape=(32,32,3),activation='relu')\n",
    "        self.max_pool2D_2 = MaxPool2D(pool_size=(2,2))\n",
    "        self.flatten = Flatten()\n",
    "        self.dense_1 = Dense(256,activation='relu')\n",
    "        self.dense_2 = Dense(10,activation='softmax')\n",
    "        \n",
    "        self.dropout = Dropout(0.3)\n",
    "        \n",
    "    def __call__(self, inputs, training=True):\n",
    "        x =  self.conv2D_1(inputs)\n",
    "        x = self.max_pool2D_1(x)\n",
    "        if training:\n",
    "            x = self.dropout(x)\n",
    "        x = self.conv2D_2(x)\n",
    "        x = self.max_pool2D_2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense_1(x)\n",
    "        x = self.dense_2(x)\n",
    "        return x\n",
    "    \n",
    "simple_conv_model_dropout  = SimpleConvModelDropout()\n",
    "\n",
    "simple_conv_model_dropout.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9feca10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dropout = simple_conv_model_dropout.fit(x=x_train, \n",
    "                      y=y_train, \n",
    "                      batch_size=512, \n",
    "                      validation_split=0.2, \n",
    "                      epochs=200,\n",
    "                      callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e484ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy(history, model_name):\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.title(model_name)\n",
    "    plt.show()\n",
    "\n",
    "def plot_loss(history, model_name):\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.title(model_name)\n",
    "    plt.show()\n",
    "def plot_history(history, model_name):\n",
    "    plot_accuracy(history, model_name)\n",
    "    plot_loss(history, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421b4664",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history_dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a813cb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185470d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmentation\n",
    "\n",
    "augmentation_model = keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.2), # zamula, wywalić, albo zastosować downgrade kerasa\n",
    "    layers.RandomZoom(0.2),\n",
    "    layers.RandomContrast(0.2),\n",
    "    layers.RandomTranslation(0.1, 0.1), \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ea2c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_augmentation = keras.Sequential([\n",
    "    augmentation_model,\n",
    "    SimpleConvModel()\n",
    "])\n",
    "\n",
    "class ModelWithAugmentation(keras.Model):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(kwargs)\n",
    "        self.nn_model = SimpleConvModel()\n",
    "        \n",
    "    def call(self, inputs, training=True):\n",
    "        print(inputs)\n",
    "        if training:\n",
    "            x = augmentation_model(inputs)\n",
    "            return self.nn_model(x)\n",
    "        else:\n",
    "            return self.nn_model(inputs)\n",
    "v2_model = ModelWithAugmentation()\n",
    "v2_model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "#simple_conv_model.build((None,32,32,3))\n",
    "model_with_augmentation.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "#model_with_augmentation.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4786b7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_for_augmentation = v2_model.fit(\n",
    "                      x=x_train, \n",
    "                      y=y_train, \n",
    "                      batch_size=256, \n",
    "                      validation_split=0.2, \n",
    "                      epochs=200,\n",
    "                      callbacks=[early_stopping_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d303a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train_augmented = x_train\n",
    "# for i in range(10):\n",
    "#     print(i)\n",
    "#     x_train_augmented = np.vstack(x_train_augmented, augmentation_model(x_train).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0843e51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_for_augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e92ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history_for_augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707736fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_names = {\n",
    "    0: \"airplane\",\n",
    "    1: \"automobile\",\n",
    "    2: \"bird\",\n",
    "    3: \"cat\",\n",
    "    4: \"deer\",\n",
    "    5: \"dog\",\n",
    "    6: \"frog\",\n",
    "    7: \"horse\",\n",
    "    8: \"ship\",\n",
    "    9: \"truck\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef323ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620c4b5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5b8a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SuperSimpleConvModelForSearch(keras.Model):\n",
    "#     def __init__(self,hp_filters_count, hp_dense_1_neurons_count, **kwargs):\n",
    "    def __init__(self, \n",
    "                 n_filters, \n",
    "                 dense_units,\n",
    "                 **kwargs):\n",
    "        super().__init__(kwargs)\n",
    "\n",
    "        self.conv2D_1 = Conv2D(filters=n_filters,kernel_size=(4,4),input_shape=(32,32,3),activation='relu')\n",
    "        self.max_pool2D_1 = MaxPool2D(pool_size=(2,2))\n",
    "        self.flatten = Flatten()\n",
    "        self.dense_1 = Dense(dense_units,activation='relu')\n",
    "        self.dense_2 = Dense(10,activation='softmax')\n",
    "        \n",
    "    def call(self, inputs, training=True):\n",
    "        print(inputs)\n",
    "        x =  self.conv2D_1(inputs)\n",
    "        x = self.max_pool2D_1(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        x = self.dense_1(x)\n",
    "        x = self.dense_2(x)\n",
    "        return x \n",
    "    \n",
    "# DORZUCIĆ funkcję hp do znalezienia najlepszego modelu dla hyperparametrów    \n",
    "def build_hp_model(hp):\n",
    "    n_filters = hp.Int(\"n_filters\", min_value=4, max_value=32, step=2, sampling=\"log\")\n",
    "    dense_units = hp.Int(\"dense_units\", min_value=16, max_value=256, step=2, sampling=\"log\")\n",
    "    # call existing model-building code with the hyperparameter values.\n",
    "    model = SuperSimpleConvModelForSearch(\n",
    "        n_filters=n_filters, dense_units=dense_units\n",
    "    )\n",
    "    model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "#super_simple_conv_model_for_search  = SuperSimpleConvModelForSearch(32, 84)\n",
    "#super_simple_conv_model_for_search.build((None, 32,32,3))\n",
    "#super_simple_conv_model_for_search.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "#super_simple_conv_model_for_search.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d23ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(build_hp_model,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=15,\n",
    "                     factor=3,\n",
    "                     directory='tuner/SuperSimpleConvModelForSearch',\n",
    "                     project_name='intro_to_kt2')\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc51df76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tuner.search(x_train, y_train, batch_size=256, epochs=50, validation_split=0.2, callbacks=[stop_early])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a88d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete\n",
    "best_hps.get('n_filters'): {best_hps.get('n_filters')},\n",
    "best_hps.get('dense_units'): {best_hps.get('dense_units')}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc66ee60",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6510c88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = build_hp_model(best_hps)\n",
    "best_model.fit(x_train, y_train, epochs=200, validation_split=0.2, batch_size=256, callbacks=[early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d21f692",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26afa803",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HPConfiguration(ABC):\n",
    "    \n",
    "    @abstractstaticmethod\n",
    "    def build_hp_model(hp):\n",
    "        pass\n",
    "    \n",
    "    @abstractstaticmethod\n",
    "    def get_tuner():\n",
    "        pass\n",
    "    \n",
    "    @abstractstaticmethod\n",
    "    def get_callbacks():\n",
    "        pass\n",
    "    \n",
    "    @abstractstaticmethod\n",
    "    def get_best_model():\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf00944c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural networks\n",
    "\n",
    "class SuperSimpleConvModel(keras.Model, HPConfiguration):\n",
    "    def __init__(self, \n",
    "                 n_filters, \n",
    "                 dense_units,\n",
    "                 **kwargs):\n",
    "        super().__init__(kwargs)\n",
    "\n",
    "        self.conv2D_1 = Conv2D(filters=n_filters,kernel_size=(4,4),input_shape=(32,32,3),activation='relu')\n",
    "        self.max_pool2D_1 = MaxPool2D(pool_size=(2,2))\n",
    "        self.flatten = Flatten()\n",
    "        self.dense_1 = Dense(dense_units,activation='relu')\n",
    "        self.dense_2 = Dense(10,activation='softmax')\n",
    "        \n",
    "    def call(self, inputs, training=True):\n",
    "        print(inputs)\n",
    "        x =  self.conv2D_1(inputs)\n",
    "        x = self.max_pool2D_1(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        x = self.dense_1(x)\n",
    "        x = self.dense_2(x)\n",
    "        return x\n",
    "   \n",
    "    def build_hp_model(hp):\n",
    "        n_filters = hp.Int(\"n_filters\", min_value=4, max_value=32, step=2, sampling=\"log\")\n",
    "        dense_units = hp.Int(\"dense_units\", min_value=16, max_value=256, step=2, sampling=\"log\")\n",
    "        model = SuperSimpleConvModel(\n",
    "            n_filters=n_filters, dense_units=dense_units\n",
    "        )\n",
    "        model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    def get_tuner():\n",
    "        return kt.Hyperband(SuperSimpleConvModel.build_hp_model,\n",
    "                            objective='val_accuracy',\n",
    "                            #overwrite=True,\n",
    "                            max_epochs=3,\n",
    "                            factor=3,\n",
    "                            directory='tuner/SuperSimpleConvModel',\n",
    "                            project_name='model'\n",
    "                           )\n",
    "    def get_callbacks():\n",
    "        return [tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)]\n",
    "    \n",
    "    def get_best_model():\n",
    "        tuner = SuperSimpleConvModel.get_tuner()\n",
    "        best_parameters = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "        return SuperSimpleConvModel.build_hp_model(best_parameters)\n",
    "    \n",
    "    \n",
    "####################\n",
    "class SimpleConvModel(keras.Model, HPConfiguration):\n",
    "    def __init__(self, \n",
    "                 n_filters_1,\n",
    "                 n_filters_2,\n",
    "                 dense_units_1,\n",
    "                 **kwargs):\n",
    "        super().__init__(kwargs)\n",
    "\n",
    "        self.conv2D_1 = Conv2D(filters=n_filters_1,kernel_size=(4,4),input_shape=(32,32,3),activation='relu')\n",
    "        self.max_pool2D_1 = MaxPool2D(pool_size=(2,2))\n",
    "        self.conv2D_2 = Conv2D(filters=n_filters_2,kernel_size=(4,4),input_shape=(32,32,3),activation='relu')\n",
    "        self.max_pool2D_2 = MaxPool2D(pool_size=(2,2))\n",
    "        self.flatten = Flatten()\n",
    "        self.dense_1 = Dense(dense_units_1,activation='relu')\n",
    "        self.dense_2 = Dense(10,activation='softmax')\n",
    "\n",
    "    def call(self, inputs, training=True):\n",
    "        print(inputs)\n",
    "        x =  self.conv2D_1(inputs)\n",
    "        x = self.max_pool2D_1(x)\n",
    "        x = self.conv2D_2(x)\n",
    "        x = self.max_pool2D_2(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense_1(x)\n",
    "        x = self.dense_2(x)\n",
    "        return x\n",
    "\n",
    "    def build_hp_model(hp):\n",
    "        n_filters_1 = hp.Int(\"n_filters_1\", min_value=4, max_value=32, step=2, sampling=\"log\")\n",
    "        n_filters_2 = hp.Int(\"n_filters_2\", min_value=2, max_value=32, step=2, sampling=\"log\")\n",
    "        dense_units_1 = hp.Int(\"dense_units_1\", min_value=16, max_value=256, step=2, sampling=\"log\")\n",
    "        model = SimpleConvModel(\n",
    "            n_filters_1=n_filters_1, n_filters_2=n_filters_2, dense_units_1=dense_units_1\n",
    "        )\n",
    "        model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    def get_tuner():\n",
    "        return kt.Hyperband(SimpleConvModel.build_hp_model,\n",
    "                            objective='val_accuracy',\n",
    "                            #overwrite=True,\n",
    "                            max_epochs=3,\n",
    "                            factor=3,\n",
    "                            directory='tuner/SuperSimpleConvModel',\n",
    "                            project_name='model'\n",
    "                           )\n",
    "    def get_callbacks():\n",
    "        return [tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)]\n",
    "                            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd1ee4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter tuning (without augmentation)\n",
    "\n",
    "SuperSimpleConvModel(16,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2cebfc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#model_classes = [SuperSimpleConvModel]\n",
    "model_classes = [SimpleConvModel]\n",
    "for model_class in model_classes:\n",
    "    print(model_class)\n",
    "    \n",
    "    tuner = model_class.get_tuner()\n",
    "    #print(tuner)\n",
    "    #tuner.search(x_train, y_train, batch_size=256, epochs=50, validation_split=0.2, callbacks=model_class.get_callbacks())\n",
    "    best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "    best_model = model_class.build_hp_model(best_hps)\n",
    "    print(best_model)\n",
    "    history = best_model.fit(x_train, y_train, epochs=200, validation_split=0.2, batch_size=256, callbacks=model_class.get_callbacks())\n",
    "    plot_history(history, model_class.__name__)\n",
    "    print('============')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bf3f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dodać powtarzalnośc wyników \n",
    "# (czyli dla każdego modelu ze znalezionymi hyperparametrami należy puścić uczenie 5 razy \n",
    "# i zobaczyć jaka jest średnia i odchykebue standarowe)\n",
    "\n",
    "# sprawdzić jakie klasy są najczęściej mylone i przygotować model \n",
    "# do rozpoznawania tylko tych mylących się klas. Połączyć następnie w całośc i sprawdzić wyniki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02dca971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing augmentation impact (na jakiejś jednej dowolnej klasie żeby sprawdzić różne warianty jak wpływają na wynik)\n",
    "# czyli np. \n",
    "# 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248fbebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# przygotować pretrenowane modele i sprawdzić wyniki (tutaj raczej nie trzeba wstawiać augmentacji danych).\n",
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
