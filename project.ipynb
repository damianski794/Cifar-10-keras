{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43498da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod, abstractstaticmethod\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import (\n",
    "    Conv2D,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    Flatten,\n",
    "    Input,\n",
    "    MaxPool2D,\n",
    "    RandomContrast,\n",
    "    RandomFlip,\n",
    "    RandomRotation, # zamula\n",
    "    RandomTranslation,\n",
    "    RandomZoom\n",
    ")\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42e35b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if GPU is detected:\n",
    "len(tf.config.list_physical_devices('GPU')) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1cc42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150ba766",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "x_train = x_train/255.0  # normalization\n",
    "x_test = x_test/255.0\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(x_train, y_train, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd7e057",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba783a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConvModel(keras.Model):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(kwargs)\n",
    "        \n",
    "        \n",
    "    #def build(self, inputs):\n",
    "        self.conv2D_1 = Conv2D(filters=32,kernel_size=(4,4),input_shape=(32,32,3),activation='relu')\n",
    "        self.max_pool2D_1 = MaxPool2D(pool_size=(2,2))\n",
    "        self.conv2D_2 = Conv2D(filters=32,kernel_size=(4,4),input_shape=(32,32,3),activation='relu')\n",
    "        self.max_pool2D_2 = MaxPool2D(pool_size=(2,2))\n",
    "        self.flatten = Flatten()\n",
    "        self.dense_1 = Dense(256,activation='relu')\n",
    "        self.dense_2 = Dense(10,activation='softmax')\n",
    "        #self.dropout = Dropout(0.3)\n",
    "        \n",
    "    def call(self, inputs, training=True):\n",
    "        print(inputs)\n",
    "        x =  self.conv2D_1(inputs)\n",
    "        x = self.max_pool2D_1(x)\n",
    "        x = self.conv2D_2(x)\n",
    "        x = self.max_pool2D_2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense_1(x)\n",
    "        x = self.dense_2(x)\n",
    "        return x        \n",
    "        \n",
    "        \n",
    "#simple_conv_model  = SimpleConvModel(inputs=Input((32,32,3)))\n",
    "simple_conv_model  = SimpleConvModel()\n",
    "simple_conv_model.build((None,32,32,3))\n",
    "#simple_conv_model.build(inputs=(32,32,3))\n",
    "simple_conv_model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "simple_conv_model.summary()\n",
    "#early_stopping = EarlyStopping(monitor='val_loss',\n",
    "#                               min_delta=0,\n",
    "#                               patience=10,\n",
    "#                               verbose=1,\n",
    "#                              )\n",
    "\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=20)\n",
    "checkpoint_callback = ModelCheckpoint('models/SimpleConvModel', \n",
    "                                      monitor='val_loss', \n",
    "                                      verbose=1, \n",
    "                                      save_best_only=True, \n",
    "                                      mode='min',\n",
    "                                      save_format='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ea8c6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = simple_conv_model.fit(\n",
    "                      x=x_train, \n",
    "                      y=y_train, \n",
    "                      batch_size=512, \n",
    "                      validation_split=0.2, \n",
    "                      epochs=100,#,\n",
    "                      callbacks=[early_stopping_callback, checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109986dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_simple_model = keras.models.load_model('models/SimpleConvModel')\n",
    "new_simple_model.evaluate(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83b7bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_conv_model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb53129a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55156231",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cc6977",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4c94f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConvModelDropout(keras.Model):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(kwargs)\n",
    "        self.conv2D_1 = Conv2D(filters=32,kernel_size=(4,4),input_shape=(32,32,3),activation='relu')\n",
    "        self.max_pool2D_1 = MaxPool2D(pool_size=(2,2))\n",
    "        self.conv2D_2 = Conv2D(filters=32,kernel_size=(4,4),input_shape=(32,32,3),activation='relu')\n",
    "        self.max_pool2D_2 = MaxPool2D(pool_size=(2,2))\n",
    "        self.flatten = Flatten()\n",
    "        self.dense_1 = Dense(256,activation='relu')\n",
    "        self.dense_2 = Dense(10,activation='softmax')\n",
    "        \n",
    "        self.dropout = Dropout(0.3)\n",
    "        \n",
    "    def __call__(self, inputs, training=True):\n",
    "        x =  self.conv2D_1(inputs)\n",
    "        x = self.max_pool2D_1(x)\n",
    "        if training:\n",
    "            x = self.dropout(x)\n",
    "        x = self.conv2D_2(x)\n",
    "        x = self.max_pool2D_2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense_1(x)\n",
    "        x = self.dense_2(x)\n",
    "        return x\n",
    "    \n",
    "simple_conv_model_dropout  = SimpleConvModelDropout()\n",
    "\n",
    "simple_conv_model_dropout.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9feca10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dropout = simple_conv_model_dropout.fit(x=x_train, \n",
    "                      y=y_train, \n",
    "                      batch_size=512, \n",
    "                      validation_split=0.2, \n",
    "                      epochs=200,\n",
    "                      callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e484ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy(history, model_name):\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.title(model_name)\n",
    "    plt.show()\n",
    "\n",
    "def plot_loss(history, model_name):\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.title(model_name)\n",
    "    plt.show()\n",
    "def plot_history(history, model_name):\n",
    "    plot_accuracy(history, model_name)\n",
    "    plot_loss(history, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421b4664",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history_dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a813cb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185470d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmentation\n",
    "\n",
    "augmentation_model = keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.2), # zamula, wywalić, albo zastosować downgrade kerasa\n",
    "    layers.RandomZoom(0.2),\n",
    "    layers.RandomContrast(0.2),\n",
    "    layers.RandomTranslation(0.1, 0.1), \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ea2c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_augmentation = keras.Sequential([\n",
    "    augmentation_model,\n",
    "    SimpleConvModel()\n",
    "])\n",
    "\n",
    "class ModelWithAugmentation(keras.Model):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(kwargs)\n",
    "        self.nn_model = SimpleConvModel()\n",
    "        \n",
    "    def call(self, inputs, training=True):\n",
    "        print(inputs)\n",
    "        if training:\n",
    "            x = augmentation_model(inputs)\n",
    "            return self.nn_model(x)\n",
    "        else:\n",
    "            return self.nn_model(inputs)\n",
    "v2_model = ModelWithAugmentation()\n",
    "v2_model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "#simple_conv_model.build((None,32,32,3))\n",
    "model_with_augmentation.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "#model_with_augmentation.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4786b7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_for_augmentation = v2_model.fit(\n",
    "                      x=x_train, \n",
    "                      y=y_train, \n",
    "                      batch_size=256, \n",
    "                      validation_split=0.2, \n",
    "                      epochs=200,\n",
    "                      callbacks=[early_stopping_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d303a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train_augmented = x_train\n",
    "# for i in range(10):\n",
    "#     print(i)\n",
    "#     x_train_augmented = np.vstack(x_train_augmented, augmentation_model(x_train).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0843e51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_for_augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e92ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history_for_augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707736fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_names = {\n",
    "    0: \"airplane\",\n",
    "    1: \"automobile\",\n",
    "    2: \"bird\",\n",
    "    3: \"cat\",\n",
    "    4: \"deer\",\n",
    "    5: \"dog\",\n",
    "    6: \"frog\",\n",
    "    7: \"horse\",\n",
    "    8: \"ship\",\n",
    "    9: \"truck\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef323ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620c4b5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5b8a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SuperSimpleConvModelForSearch(keras.Model):\n",
    "#     def __init__(self,hp_filters_count, hp_dense_1_neurons_count, **kwargs):\n",
    "    def __init__(self, \n",
    "                 n_filters, \n",
    "                 dense_units,\n",
    "                 **kwargs):\n",
    "        super().__init__(kwargs)\n",
    "\n",
    "        self.conv2D_1 = Conv2D(filters=n_filters,kernel_size=(4,4),input_shape=(32,32,3),activation='relu')\n",
    "        self.max_pool2D_1 = MaxPool2D(pool_size=(2,2))\n",
    "        self.flatten = Flatten()\n",
    "        self.dense_1 = Dense(dense_units,activation='relu')\n",
    "        self.dense_2 = Dense(10,activation='softmax')\n",
    "        \n",
    "    def call(self, inputs, training=True):\n",
    "        print(inputs)\n",
    "        x =  self.conv2D_1(inputs)\n",
    "        x = self.max_pool2D_1(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        x = self.dense_1(x)\n",
    "        x = self.dense_2(x)\n",
    "        return x \n",
    "    \n",
    "# DORZUCIĆ funkcję hp do znalezienia najlepszego modelu dla hyperparametrów    \n",
    "def build_hp_model(hp):\n",
    "    n_filters = hp.Int(\"n_filters\", min_value=4, max_value=32, step=2, sampling=\"log\")\n",
    "    dense_units = hp.Int(\"dense_units\", min_value=16, max_value=256, step=2, sampling=\"log\")\n",
    "    # call existing model-building code with the hyperparameter values.\n",
    "    model = SuperSimpleConvModelForSearch(\n",
    "        n_filters=n_filters, dense_units=dense_units\n",
    "    )\n",
    "    model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "#super_simple_conv_model_for_search  = SuperSimpleConvModelForSearch(32, 84)\n",
    "#super_simple_conv_model_for_search.build((None, 32,32,3))\n",
    "#super_simple_conv_model_for_search.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "#super_simple_conv_model_for_search.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d23ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(build_hp_model,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=15,\n",
    "                     factor=3,\n",
    "                     directory='tuner/SuperSimpleConvModelForSearch',\n",
    "                     project_name='intro_to_kt2')\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc51df76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tuner.search(x_train, y_train, batch_size=256, epochs=50, validation_split=0.2, callbacks=[stop_early])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a88d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete\n",
    "best_hps.get('n_filters'): {best_hps.get('n_filters')},\n",
    "best_hps.get('dense_units'): {best_hps.get('dense_units')}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc66ee60",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6510c88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = build_hp_model(best_hps)\n",
    "best_model.fit(x_train, y_train, epochs=200, validation_split=0.2, batch_size=256, callbacks=[early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d21f692",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26afa803",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HPConfiguration(ABC):\n",
    "    \n",
    "    @abstractstaticmethod\n",
    "    def build_hp_model(hp):\n",
    "        pass\n",
    "    \n",
    "    @abstractstaticmethod\n",
    "    def get_tuner():\n",
    "        pass\n",
    "    \n",
    "    @abstractstaticmethod\n",
    "    def get_callbacks():\n",
    "        pass\n",
    "    \n",
    "    @abstractstaticmethod\n",
    "    def get_tuner_callbacks():\n",
    "        pass\n",
    "    #@abstractstaticmethod\n",
    "    #def get_best_model():\n",
    "    #    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf00944c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural networks\n",
    "\n",
    "class SuperSimpleConvModel(keras.Model, HPConfiguration):\n",
    "    def __init__(self, \n",
    "                 n_filters, \n",
    "                 dense_units,\n",
    "                 **kwargs):\n",
    "        super().__init__(kwargs)\n",
    "\n",
    "        self.conv2D_1 = Conv2D(filters=n_filters,kernel_size=(4,4),input_shape=(32,32,3),activation='relu')\n",
    "        self.max_pool2D_1 = MaxPool2D(pool_size=(2,2))\n",
    "        self.flatten = Flatten()\n",
    "        self.dense_1 = Dense(dense_units,activation='relu')\n",
    "        self.dense_2 = Dense(10,activation='softmax')\n",
    "        \n",
    "    def call(self, inputs, training=True):\n",
    "        #print(inputs)\n",
    "        x =  self.conv2D_1(inputs)\n",
    "        x = self.max_pool2D_1(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        x = self.dense_1(x)\n",
    "        x = self.dense_2(x)\n",
    "        return x\n",
    "   \n",
    "    def build_hp_model(hp):\n",
    "        n_filters = hp.Int(\"n_filters\", min_value=4, max_value=32, step=2, sampling=\"log\")\n",
    "        dense_units = hp.Int(\"dense_units\", min_value=16, max_value=256, step=2, sampling=\"log\")\n",
    "        model = SuperSimpleConvModel(\n",
    "            n_filters=n_filters, dense_units=dense_units\n",
    "        )\n",
    "        model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    def get_tuner():\n",
    "        return kt.Hyperband(SuperSimpleConvModel.build_hp_model,\n",
    "                            objective='val_accuracy',\n",
    "                            #overwrite=True,\n",
    "                            max_epochs=50,\n",
    "                            factor=3,\n",
    "                            directory='tuner/SuperSimpleConvModel',\n",
    "                            project_name='model'\n",
    "                           )\n",
    "    def get_callbacks():\n",
    "        return [\n",
    "            tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20),\n",
    "            #tf.keras.callbacks.ModelCheckpoint(filepath=\"models/SuperSimpleConvModel\", save_best_only=True)\n",
    "        ]\n",
    "    \n",
    "    def get_tuner_callbacks():\n",
    "        return [\n",
    "            tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20),\n",
    "        ]\n",
    "    \n",
    "    def get_best_model():\n",
    "        tuner = SuperSimpleConvModel.get_tuner()\n",
    "        best_parameters = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "        return SuperSimpleConvModel.build_hp_model(best_parameters)\n",
    "    \n",
    "    \n",
    "####################\n",
    "class SimpleConvModel(keras.Model, HPConfiguration):\n",
    "    def __init__(self, \n",
    "                 n_filters_1,\n",
    "                 n_filters_2,\n",
    "                 dense_units_1,\n",
    "                 **kwargs):\n",
    "        super().__init__(kwargs)\n",
    "\n",
    "        self.conv2D_1 = Conv2D(filters=n_filters_1,kernel_size=(4,4),input_shape=(32,32,3),activation='relu')\n",
    "        self.max_pool2D_1 = MaxPool2D(pool_size=(2,2))\n",
    "        self.conv2D_2 = Conv2D(filters=n_filters_2,kernel_size=(4,4),input_shape=(32,32,3),activation='relu')\n",
    "        self.max_pool2D_2 = MaxPool2D(pool_size=(2,2))\n",
    "        self.flatten = Flatten()\n",
    "        self.dense_1 = Dense(dense_units_1,activation='relu')\n",
    "        self.dense_2 = Dense(10,activation='softmax')\n",
    "\n",
    "    def call(self, inputs, training=True):\n",
    "        #print(inputs)\n",
    "        x =  self.conv2D_1(inputs)\n",
    "        x = self.max_pool2D_1(x)\n",
    "        x = self.conv2D_2(x)\n",
    "        x = self.max_pool2D_2(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense_1(x)\n",
    "        x = self.dense_2(x)\n",
    "        return x\n",
    "\n",
    "    def build_hp_model(hp):\n",
    "        n_filters_1 = hp.Int(\"n_filters_1\", min_value=4, max_value=32, step=2, sampling=\"log\")\n",
    "        n_filters_2 = hp.Int(\"n_filters_2\", min_value=2, max_value=32, step=2, sampling=\"log\")\n",
    "        dense_units_1 = hp.Int(\"dense_units_1\", min_value=16, max_value=256, step=2, sampling=\"log\")\n",
    "        model = SimpleConvModel(\n",
    "            n_filters_1=n_filters_1, n_filters_2=n_filters_2, dense_units_1=dense_units_1\n",
    "        )\n",
    "        model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    def get_tuner():\n",
    "        return kt.Hyperband(SimpleConvModel.build_hp_model,\n",
    "                            objective='val_accuracy',\n",
    "                            #overwrite=True,\n",
    "                            max_epochs=50,\n",
    "                            factor=3,\n",
    "                            directory='tuner/SimpleConvModel',\n",
    "                            project_name='model'\n",
    "                           )\n",
    "    def get_callbacks():\n",
    "        return [\n",
    "            tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20),\n",
    "            #tf.keras.callbacks.ModelCheckpoint(filepath=\"models/SimpleConvModel\", save_best_only=True)\n",
    "        ]\n",
    "    \n",
    "    def get_tuner_callbacks():\n",
    "        return [\n",
    "            tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20),\n",
    "        ]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd1ee4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter tuning (without augmentation)\n",
    "\n",
    "SuperSimpleConvModel(16,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d34a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_classes = [SuperSimpleConvModel, SimpleConvModel]\n",
    "\n",
    "for model_class in model_classes:\n",
    "    print(model_class)\n",
    "    # break\n",
    "    tuner = model_class.get_tuner()\n",
    "    #print(tuner)\n",
    "    tuner.search(x_train, y_train, batch_size=256, epochs=50, validation_data=(x_validation, y_validation), callbacks=model_class.get_tuner_callbacks())\n",
    "    best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0068837",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_results = {\n",
    "    model_class.__name__ + \"_\" + str_type: [] for model_class in model_classes for str_type in [\"train\", \"validation\", \"test\"]\n",
    "}\n",
    "\n",
    "print(accuracy_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a96979b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2cebfc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_classes = [SimpleConvModel]\n",
    "#model_classes = [SuperSimpleConvModel, SimpleConvModel]\n",
    "\n",
    "for model_class in model_classes:\n",
    "    tuner = model_class.get_tuner()\n",
    "    best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "    print(best_hps.values)\n",
    "    #best_hps.\n",
    "    \n",
    "    \n",
    "    for replication in range(4):\n",
    "        print(f'Starting {replication} iteration')\n",
    "        best_model = model_class.build_hp_model(best_hps)\n",
    "        print(best_model)\n",
    "        history = best_model.fit(x_train, y_train, epochs=200, validation_data=(x_validation, y_validation), batch_size=256, callbacks=model_class.get_callbacks(), verbose=0)\n",
    "        print(f\"model name: {model_class.__name__}\")\n",
    "        print(f\"iteration: {replication}\")\n",
    "        train_loss, train_accuracy = best_model.evaluate(x=x_train, y=y_train)\n",
    "        accuracy_results[model_class.__name__ + \"_train\"].append(train_accuracy)\n",
    "        validation_loss, validation_accuracy = best_model.evaluate(x=x_validation, y=y_validation)\n",
    "        accuracy_results[model_class.__name__ + \"_validation\"].append(validation_accuracy)\n",
    "        test_loss, test_accuracy = best_model.evaluate(x=x_test, y=y_test)\n",
    "        accuracy_results[model_class.__name__ + \"_test\"].append(test_accuracy)\n",
    "        print(f\"train accuracy: {train_accuracy}\")\n",
    "        print(f\"validation accuracy: {validation_accuracy}\")\n",
    "        print(f\"test accuracy: {test_accuracy}\")\n",
    "        plot_history(history, model_class.__name__)\n",
    "        \n",
    "        print('============ NEW ITERATION ============')\n",
    "\n",
    "print(accuracy_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274b0ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_type, accuracy_list in accuracy_results.items():\n",
    "    avg = np.average(accuracy_list)\n",
    "    std = np.std(accuracy_list)\n",
    "    minimal = np.min(accuracy_list)\n",
    "    maximal = np.max(accuracy_list)\n",
    "    print(f\"mode: {model_type}, avg: {avg}, std: {std}, min: {minimal}, max: {maximal}\")\n",
    "    print('==============')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f4e471",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_type, accuracy_list in accuracy_results.items():\n",
    "    plt.plot(accuracy_list, label=model_type)\n",
    "    #plt.violinplot(accuracy_list)\n",
    "plt.legend()\n",
    "y_min = min(min(accuracy_list) for accuracy_list in accuracy_results.values())\n",
    "y_max = max(max(accuracy_list) for accuracy_list in accuracy_results.values()) \n",
    "plt.ylim(y_min, y_max*1.2)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bf3f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dodać powtarzalnośc wyników \n",
    "# (czyli dla każdego modelu ze znalezionymi hyperparametrami należy puścić uczenie 5 razy \n",
    "# i zobaczyć jaka jest średnia i odchykebue standarowe)\n",
    "\n",
    "# sprawdzić jakie klasy są najczęściej mylone i przygotować model \n",
    "# do rozpoznawania tylko tych mylących się klas. Połączyć następnie w całośc i sprawdzić wyniki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02dca971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing augmentation impact (na jakiejś jednej dowolnej klasie żeby sprawdzić różne warianty jak wpływają na wynik)\n",
    "# czyli np. \n",
    "# 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248fbebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# przygotować pretrenowane modele i sprawdzić wyniki (tutaj raczej nie trzeba wstawiać augmentacji danych).\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5fa5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmentations variants\n",
    "\n",
    "augmentation_random_flip =keras.Sequential([\n",
    "    RandomFlip(\"horizontal\")\n",
    "], name='augmentation_random_flip')\n",
    "\n",
    "augmentation_random_zoom =keras.Sequential([\n",
    "    RandomZoom(0.2)\n",
    "], name='augmentation_random_zoom')\n",
    "\n",
    "augmentation_random_rotation = keras.Sequential([\n",
    "    RandomRotation(0.2)\n",
    "], name='augmentation_random_rotation')\n",
    "\n",
    "\n",
    "augmentation_random_translation = keras.Sequential([\n",
    "    RandomTranslation(0.1, 0.1)\n",
    "], name='augmentation_random_translation')\n",
    "\n",
    "augmentation_random_contrast = keras.Sequential([\n",
    "    RandomContrast(0.1)\n",
    "], name='augmentation_random_contrast')\n",
    "\n",
    "augmentation_combined = keras.Sequential([\n",
    "    RandomFlip(\"horizontal\"),\n",
    "    RandomZoom(0.2),\n",
    "    RandomRotation(0.2),\n",
    "    RandomTranslation(0.1, 0.1),\n",
    "    RandomContrast(0.1)\n",
    "], name='augmentation_combined')\n",
    "\n",
    "augmentation_random_flip_translation = keras.Sequential([\n",
    "    RandomFlip(\"horizontal\"),\n",
    "    RandomTranslation(0.1, 0.1),\n",
    "], name='augmentation_random_flip_translation')\n",
    "\n",
    "augmentation_random_flip_translation_zoom = keras.Sequential([\n",
    "    RandomFlip(\"horizontal\"),\n",
    "    RandomTranslation(0.1, 0.1),\n",
    "    RandomZoom(0.2)\n",
    "], name='augmentation_random_flip_translation_zoom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd752e49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "augmentations = [\n",
    "    #augmentation_random_flip,\n",
    "    #augmentation_random_zoom,\n",
    "    #augmentation_random_rotation,\n",
    "    #augmentation_random_translation,\n",
    "    #augmentation_random_contrast,\n",
    "    augmentation_combined\n",
    "    #augmentation_random_flip_translation,\n",
    "    #augmentation_random_flip_translation_zoom\n",
    "]\n",
    "\n",
    "augmentation_results = {\n",
    "    augmentation.name + \"_\" + str_type: [] for augmentation in augmentations for str_type in [\"train\", \"validation\", \"test\"]\n",
    "}\n",
    "print(augmentation_results)\n",
    "for augmentation in augmentations:\n",
    "    for replication in range(5):\n",
    "        model = keras.Sequential([\n",
    "        augmentation,\n",
    "        SimpleConvModel(n_filters_1=32,\n",
    "                       n_filters_2=32,\n",
    "                       dense_units_1=64)])\n",
    "        model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "        history = model.fit(x_train, \n",
    "                            y_train, \n",
    "                            epochs=400, \n",
    "                            validation_data=(x_validation, y_validation), \n",
    "                            batch_size=256, \n",
    "                            #callbacks=SimpleConvModel.get_callbacks()\n",
    "                            callbacks=EarlyStopping(patience=50,monitor='val_loss')\n",
    "                           )\n",
    "        print(f\"augmentation name: {augmentation.name}\")\n",
    "        print(f\"iteration: {replication}\")\n",
    "        train_loss, train_accuracy = model.evaluate(x=x_train, y=y_train)\n",
    "        augmentation_results[augmentation.name + \"_train\"].append(train_accuracy)\n",
    "        validation_loss, validation_accuracy = model.evaluate(x=x_validation, y=y_validation)\n",
    "        augmentation_results[augmentation.name + \"_validation\"].append(validation_accuracy)\n",
    "        test_loss, test_accuracy = model.evaluate(x=x_test, y=y_test)\n",
    "        augmentation_results[augmentation.name + \"_test\"].append(test_accuracy)\n",
    "        print(f\"train accuracy: {train_accuracy}\")\n",
    "        print(f\"validation accuracy: {validation_accuracy}\")\n",
    "        print(f\"test accuracy: {test_accuracy}\")\n",
    "        plot_history(history, augmentation.name)\n",
    "        \n",
    "        print('============ NEW ITERATION ============')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207e4f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf710238",
   "metadata": {},
   "outputs": [],
   "source": [
    "for augmentation_name, accuracy_list in augmentation_results.items():\n",
    "    avg = np.average(accuracy_list)\n",
    "    std = np.std(accuracy_list)\n",
    "    minimal = np.min(accuracy_list)\n",
    "    maximal = np.max(accuracy_list)\n",
    "    \n",
    "    print(f\"mode: {augmentation_name}, avg: {avg}, std: {std}, min: {minimal}, max: {maximal}\")\n",
    "    print('===')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a940edc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "augmentation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97490309",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed5172d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
