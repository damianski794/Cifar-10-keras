{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tensorflow import keras\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPool2D\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "labels = ['Airplane', 'Automobile', 'Bird', 'Cat',\n",
    "          'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if GPU is detected:\n",
    "len(tf.config.list_physical_devices('GPU')) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Preprocessing\n",
    "\n",
    "x_train_16 = tf.keras.applications.vgg16.preprocess_input(x_train)\n",
    "x_test_16 = tf.keras.applications.vgg16.preprocess_input(x_test)\n",
    "\n",
    "x_train_19 = tf.keras.applications.vgg19.preprocess_input(x_train)\n",
    "x_test_19 = tf.keras.applications.vgg19.preprocess_input(x_test)\n",
    "\n",
    "x_train_resnet = tf.keras.applications.resnet.preprocess_input(x_train)\n",
    "x_test_resnet = tf.keras.applications.resnet.preprocess_input(x_test)\n",
    "\n",
    "\n",
    "# Split into train and validation\n",
    "\n",
    "x_train_16, x_validation_16, y_train_16, y_validation_16 = train_test_split(\n",
    "    x_train_16, y_train, train_size=0.8)\n",
    "\n",
    "x_train_19, x_validation_19, y_train_19, y_validation_19 = train_test_split(\n",
    "    x_train_19, y_train, train_size=0.8)\n",
    "\n",
    "x_train_resnet, x_validation_resnet, y_train_resnet, y_validation_resnet = train_test_split(\n",
    "    x_train_resnet, y_train, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawConfMatrix(model, x_test, y_test, labels):\n",
    "    predictions = model.predict(x_test, verbose=True)\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "    confMat = ConfusionMatrixDisplay(confusion_matrix(y_test, predictions, normalize='true'), display_labels=labels)\n",
    "    fig, ax = pyplot.subplots(figsize=(8,8))\n",
    "    confMat.plot(ax = ax,  xticks_rotation = 'vertical')\n",
    "\n",
    "def plot_accuracy(history, model_name):\n",
    "    plt.plot(history['accuracy'])\n",
    "    plt.plot(history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.title(model_name)\n",
    "    plt.show()\n",
    "\n",
    "def plot_loss(history, model_name):\n",
    "    plt.plot(history['loss'])\n",
    "    plt.plot(history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.title(model_name)\n",
    "    plt.show()\n",
    "\n",
    "def plot_history(history, model_name):\n",
    "    plot_accuracy(history, model_name)\n",
    "    plot_loss(history, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vgg_model(con_base, n_classes, optimizer, fine_tune=False):\n",
    "\n",
    "    conv_base = con_base\n",
    "    \n",
    "    for layer in conv_base.layers:\n",
    "        layer.trainable = fine_tune\n",
    "\n",
    "    top_model = conv_base.output\n",
    "    top_model = Flatten()(top_model)\n",
    "    top_model = Dense(4096, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.5)(top_model)\n",
    "    top_model = Dense(4096, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.5)(top_model)\n",
    "    output_layer = Dense(n_classes, activation='softmax')(top_model)\n",
    "\n",
    "    model = Model(inputs=conv_base.input, outputs=output_layer)\n",
    "\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "def create_resnet_model(con_base, n_classes, optimizer, fine_tune=False):\n",
    "\n",
    "    conv_base = con_base\n",
    "\n",
    "    for layer in conv_base.layers:\n",
    "        layer.trainable = fine_tune\n",
    "\n",
    "    top_model = conv_base.output\n",
    "    top_model = Flatten()(top_model)\n",
    "    top_model = Dense(1024, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.3)(top_model)\n",
    "    output_layer = Dense(n_classes, activation='softmax')(top_model)\n",
    "\n",
    "    model = Model(inputs=conv_base.input, outputs=output_layer)\n",
    "\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (32, 32, 3)\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.9)\n",
    "n_classes = 10\n",
    "n_epochs = 250\n",
    "vgg16 = tf.keras.applications.VGG16(include_top=False,\n",
    "                                    weights='imagenet',\n",
    "                                    input_shape=input_shape)\n",
    "\n",
    "vgg19 = tf.keras.applications.VGG19(include_top=False,\n",
    "                                    weights='imagenet',\n",
    "                                    input_shape=input_shape)\n",
    "\n",
    "resnet = tf.keras.applications.ResNet50(include_top=False,\n",
    "                                    weights='imagenet',\n",
    "                                    input_shape=input_shape)\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss',\n",
    "                           patience=10,\n",
    "                           restore_best_weights=True,\n",
    "                           mode='min')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG 16 Pretrained - FULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(5):\n",
    "#     keras.backend.clear_session()\n",
    "\n",
    "#     vgg_model = create_vgg_model(vgg16, n_classes, optimizer, fine_tune=False)\n",
    "#     vgg_history = vgg_model.fit(x_train_16, y_train_16,\n",
    "#                             batch_size=32,\n",
    "#                             epochs=n_epochs,\n",
    "#                             validation_data=(x_validation_16, y_validation_16),\n",
    "#                             callbacks=[early_stop],\n",
    "#                             verbose=1)\n",
    "#     vgg_model.save('models/vgg16_/' + str(i))\n",
    "#     with open('./train_history/vgg16_' + str(i), 'wb') as file_pi:\n",
    "#         pickle.dump(vgg_history.history, file_pi)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG 19 Pretrained - FULL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(5):\n",
    "#     keras.backend.clear_session()\n",
    "\n",
    "#     vgg_model = create_vgg_model(vgg19, n_classes, optimizer, fine_tune=False)\n",
    "#     vgg_history = vgg_model.fit(x_train_19, y_train_19,\n",
    "#                             batch_size=32,\n",
    "#                             epochs=n_epochs,\n",
    "#                             validation_data=(x_validation_19, y_validation_19),\n",
    "#                             callbacks=[early_stop],\n",
    "#                             verbose=1)\n",
    "#     vgg_model.save('models/vgg19_/' + str(i))\n",
    "#     with open('./train_history/vgg19_' + str(i), 'wb') as file_pi:\n",
    "#         pickle.dump(vgg_history.history, file_pi)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG 16 Pretrained & Fine Tuned - FULL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(5):\n",
    "#     keras.backend.clear_session()\n",
    "#     vgg16 = tf.keras.applications.VGG16(include_top=False,\n",
    "#                                     weights='imagenet',\n",
    "#                                     input_shape=input_shape)\n",
    "#     vgg_model = create_vgg_model(vgg16, n_classes, optimizer, fine_tune=True)\n",
    "#     vgg_history = vgg_model.fit(x_train_16, y_train_16,\n",
    "#                             batch_size=32,\n",
    "#                             epochs=n_epochs,\n",
    "#                             validation_data=(x_validation_16, y_validation_16),\n",
    "#                             callbacks=[early_stop],\n",
    "#                             verbose=1)\n",
    "#     vgg_model.save('models/vgg16ft_/' + str(i))\n",
    "#     with open('./train_history/vgg16ft_' + str(i), 'wb') as file_pi:\n",
    "#         pickle.dump(vgg_history.history, file_pi)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG 19 Pretrained & Fine Tuned - FULL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(5):\n",
    "#     keras.backend.clear_session()\n",
    "#     vgg19 = tf.keras.applications.VGG19(include_top=False,\n",
    "#                                     weights='imagenet',\n",
    "#                                     input_shape=input_shape)\n",
    "#     vgg_model = create_vgg_model(vgg19, n_classes, optimizer, fine_tune=True)\n",
    "#     vgg_history = vgg_model.fit(x_train_19, y_train_19,\n",
    "#                             batch_size=32,\n",
    "#                             epochs=n_epochs,\n",
    "#                             validation_data=(x_validation_19, y_validation_19),\n",
    "#                             callbacks=[early_stop],\n",
    "#                             verbose=1)\n",
    "#     vgg_model.save('models/vgg19ft_/' + str(i))\n",
    "#     with open('./train_history/vgg19ft_' + str(i), 'wb') as file_pi:\n",
    "#         pickle.dump(vgg_history.history, file_pi)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG 16 No pretraining - FULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(5):\n",
    "#     keras.backend.clear_session()\n",
    "#     vgg16 = tf.keras.applications.VGG16(include_top=False,\n",
    "#                                     weights=None,\n",
    "#                                     input_shape=input_shape)\n",
    "#     vgg_model = create_vgg_model(vgg16, n_classes, optimizer, fine_tune=True)\n",
    "#     vgg_history = vgg_model.fit(x_train_16, y_train_16,\n",
    "#                             batch_size=32,\n",
    "#                             epochs=n_epochs,\n",
    "#                             validation_data=(x_validation_16, y_validation_16),\n",
    "#                             callbacks=[early_stop],\n",
    "#                             verbose=1)\n",
    "#     vgg_model.save('models/vgg16_clean_/' + str(i))\n",
    "#     with open('./train_history/vgg16_clean_' + str(i), 'wb') as file_pi:\n",
    "#         pickle.dump(vgg_history.history, file_pi)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG 19 No pretraining - FULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(5):\n",
    "#     keras.backend.clear_session()\n",
    "#     vgg19 = tf.keras.applications.VGG19(include_top=False,\n",
    "#                                     weights=None,\n",
    "#                                     input_shape=input_shape)\n",
    "#     vgg_model = create_vgg_model(vgg19, n_classes, optimizer, fine_tune=True)\n",
    "#     vgg_history = vgg_model.fit(x_train_19, y_train_19,\n",
    "#                             batch_size=32,\n",
    "#                             epochs=n_epochs,\n",
    "#                             validation_data=(x_validation_19, y_validation_19),\n",
    "#                             callbacks=[early_stop],\n",
    "#                             verbose=1)\n",
    "#     vgg_model.save('models/vgg19_clean_/' + str(i))\n",
    "#     with open('./train_history/vgg19_clean_' + str(i), 'wb') as file_pi:\n",
    "#         pickle.dump(vgg_history.history, file_pi)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet50 Pretrained - FULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(5):\n",
    "#     keras.backend.clear_session()\n",
    "\n",
    "#     resnet_model = create_resnet_model(resnet, n_classes, optimizer, fine_tune=False)\n",
    "#     resnet_history = resnet_model.fit(x_train_resnet, y_train_resnet,\n",
    "#                             batch_size=32,\n",
    "#                             epochs=n_epochs,\n",
    "#                             validation_data=(x_validation_resnet, y_validation_resnet),\n",
    "#                             callbacks=[early_stop],\n",
    "#                             verbose=1)\n",
    "#     resnet_model.save('models/resnet/' + str(i))\n",
    "#     with open('./train_history/resnet_' + str(i), 'wb') as file_pi:\n",
    "#         pickle.dump(resnet_history.history, file_pi)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet50 No Pretraining - FULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(5):\n",
    "#     keras.backend.clear_session()\n",
    "#     resnet = tf.keras.applications.ResNet50(include_top=False,\n",
    "#                                     weights=None,\n",
    "#                                     input_shape=input_shape)\n",
    "#     resnet_model = create_resnet_model(resnet, n_classes, optimizer, fine_tune=True)\n",
    "#     resnet_history = resnet_model.fit(x_train_resnet, y_train_resnet,\n",
    "#                             batch_size=32,\n",
    "#                             epochs=n_epochs,\n",
    "#                             validation_data=(x_validation_resnet, y_validation_resnet),\n",
    "#                             callbacks=[early_stop],\n",
    "#                             verbose=1)\n",
    "#     resnet_model.save('models/resnet_clean_/' + str(i))\n",
    "#     with open('./train_history/resnet_clean_' + str(i), 'wb') as file_pi:\n",
    "#         pickle.dump(resnet_history.history, file_pi)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet50 Pretrained & unfrozen - FULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(5):\n",
    "#     keras.backend.clear_session()\n",
    "#     resnet = tf.keras.applications.ResNet50(include_top=False,\n",
    "#                                     weights='imagenet',\n",
    "#                                     input_shape=input_shape)\n",
    "#     resnet_model = create_resnet_model(resnet, n_classes, optimizer, fine_tune=True)\n",
    "#     resnet_history = resnet_model.fit(x_train_resnet, y_train_resnet,\n",
    "#                             batch_size=32,\n",
    "#                             epochs=n_epochs,\n",
    "#                             validation_data=(x_validation_resnet, y_validation_resnet),\n",
    "#                             callbacks=[early_stop],\n",
    "#                             verbose=1)\n",
    "#     resnet_model.save('models/resnet_ft_/' + str(i))\n",
    "#     with open('./train_history/resnet_ft_' + str(i), 'wb') as file_pi:\n",
    "#         pickle.dump(resnet_history.history, file_pi)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder_path = 'models/advd02/'\n",
    "# accuracies = []\n",
    "\n",
    "# for i in range(5):\n",
    "#     model = keras.models.load_model(folder_path + str(i))\n",
    "#     test_loss, test_accuracy = model.evaluate(x=x_test, y=y_test) \n",
    "#     accuracies.append(test_accuracy)\n",
    "\n",
    "# avg = np.average(accuracies)\n",
    "# std = np.std(accuracies)\n",
    "# minimal = np.min(accuracies)\n",
    "# maximal = np.max(accuracies)\n",
    "# print(f\"model: {folder_path}, avg: {avg}, std: {std}, min: {minimal}, max: {maximal}\")\n",
    "# print('==============')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hisotry reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = './train_history/adv_d02_0'\n",
    "# #filename = './train_history/vgg16_0'\n",
    "\n",
    "# with open(filename, \"rb\") as file_pi:\n",
    "#     history = pickle.load(file_pi)\n",
    "\n",
    "# plot_history(history, 'AdvancedConvModelDropout')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_advanced_model(dropout = 0.0):\n",
    "    model = keras.Sequential()\n",
    "    model.add(Conv2D(filters=32,kernel_size=(4,4),input_shape=(32,32,3),activation='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    if dropout > 0.0:\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Conv2D(filters=32,kernel_size=(4,4),activation='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    if dropout > 0.0:\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Conv2D(filters=32,kernel_size=(4,4),activation='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    if dropout > 0.0:\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256,activation='relu'))\n",
    "    if dropout > 0.0:\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "def create_advanced_model_with_reg(reg, dropout = 0.0):\n",
    "    model = keras.Sequential()\n",
    "    model.add(Conv2D(filters=32,kernel_size=(4,4),input_shape=(32,32,3),activation='relu', kernel_regularizer=reg))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    if dropout > 0.0:\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Conv2D(filters=32,kernel_size=(4,4),activation='relu', kernel_regularizer=reg))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    if dropout > 0.0:\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Conv2D(filters=32,kernel_size=(4,4),activation='relu', kernel_regularizer=reg))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    if dropout > 0.0:\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256,activation='relu', kernel_regularizer=reg))\n",
    "    if dropout > 0.0:\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss',\n",
    "                           patience=20,\n",
    "                           restore_best_weights=False,\n",
    "                           mode='min')\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "x_train = x_train / 255.0  # normalization\n",
    "x_test = x_test / 255.0\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(x_train, y_train, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(5):\n",
    "#     keras.backend.clear_session()\n",
    "#     advanced_model =  create_advanced_model()\n",
    "#     advanced_model_history = advanced_model.fit(x_train, y_train,\n",
    "#                             batch_size=32,\n",
    "#                             epochs=n_epochs,\n",
    "#                             validation_data=(x_validation, y_validation),\n",
    "#                             callbacks=[early_stop],\n",
    "#                             verbose=1)\n",
    "#     advanced_model.save('models/adv/' + str(i))\n",
    "#     with open('./train_history/adv' + str(i), 'wb') as file_pi:\n",
    "#         pickle.dump(advanced_model_history.history, file_pi)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropout - FULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(5):\n",
    "#     keras.backend.clear_session()\n",
    "#     advanced_model =  create_advanced_model(0.2)\n",
    "#     advanced_model_history = advanced_model.fit(x_train, y_train,\n",
    "#                             batch_size=32,\n",
    "#                             epochs=500,\n",
    "#                             validation_data=(x_validation, y_validation),\n",
    "#                             callbacks=[early_stop],\n",
    "#                             verbose=1)\n",
    "#     advanced_model.save('models/advd02/' + str(i))\n",
    "#     with open('./train_history/adv_d02_' + str(i), 'wb') as file_pi:\n",
    "#         pickle.dump(advanced_model_history.history, file_pi)\n",
    "\n",
    "# for i in range(5):\n",
    "#     keras.backend.clear_session()\n",
    "#     advanced_model =  create_advanced_model(0.1)\n",
    "#     advanced_model_history = advanced_model.fit(x_train, y_train,\n",
    "#                             batch_size=32,\n",
    "#                             epochs=500,\n",
    "#                             validation_data=(x_validation, y_validation),\n",
    "#                             callbacks=[early_stop],\n",
    "#                             verbose=1)\n",
    "#     advanced_model.save('models/advd01/' + str(i))\n",
    "#     with open('./train_history/adv_d01_' + str(i), 'wb') as file_pi:\n",
    "#         pickle.dump(advanced_model_history.history, file_pi)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regulizer L2 - FULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.regularizers import l2\n",
    "\n",
    "# for i in range(5):\n",
    "#     keras.backend.clear_session()\n",
    "#     advanced_model =  create_advanced_model_with_reg(l2(0.01))\n",
    "#     advanced_model_history = advanced_model.fit(x_train, y_train,\n",
    "#                             batch_size=32,\n",
    "#                             epochs=n_epochs,\n",
    "#                             validation_data=(x_validation, y_validation),\n",
    "#                             callbacks=[early_stop],\n",
    "#                             verbose=1)\n",
    "#     advanced_model.save('models/adv_reg001/' + str(i))\n",
    "#     with open('./train_history/adv_reg001_' + str(i), 'wb') as file_pi:\n",
    "#         pickle.dump(advanced_model_history.history, file_pi)\n",
    "\n",
    "# for i in range(5):\n",
    "#     keras.backend.clear_session()\n",
    "#     advanced_model =  create_advanced_model_with_reg(l2(0.001))\n",
    "#     advanced_model_history = advanced_model.fit(x_train, y_train,\n",
    "#                             batch_size=32,\n",
    "#                             epochs=n_epochs,\n",
    "#                             validation_data=(x_validation, y_validation),\n",
    "#                             callbacks=[early_stop],\n",
    "#                             verbose=1)\n",
    "#     advanced_model.save('models/adv_reg001/' + str(i))\n",
    "#     with open('./train_history/adv_reg001_' + str(i), 'wb') as file_pi:\n",
    "#         pickle.dump(advanced_model_history.history, file_pi)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
